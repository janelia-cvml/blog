[
  {
    "objectID": "posts/FourCastNet/index.html",
    "href": "posts/FourCastNet/index.html",
    "title": "FourCastNet",
    "section": "",
    "text": "Neural Operators and Fourier Neural Operator papers were presented by Michael Innerberger and Magdalena Schneider in Janelia CVML 2024-11-01, Adaptive Fourier Neural Operator and FourCastNet papers were presented by Magdalena Schneider and Kristin Branson in Janelia CVML 2024-11-08\nTo date, weather forecasts are based on numerical weather prediction: numerical integration of partial differential equations (PDEs) describing atmospheric motion from measured initial conditions. The equations governing weather have been researched since the early 1900s [Lynch, 2008], and numerically solving these PDEs was an early success of computers [Charney, 1952]. Steady improvements in forecasting accuracy have been made, including improved data and data assimilation and numerical methods (Figure 1).\nThere’s a pretty remarkable dataset available in the realm of AI for science: the ERA5 global reanalysis dataset, which contains hourly estimates of numerous 3D atmospheric, land, and ocean features at a horizontal resolution of 30 km over the past 80 years. This dataset was synthesized from up to 25M-per-day measurements from Earth-observing satellites and weather stations. Can machine learning be used to learn to forecast the weather better, either by more efficiently/effectively solving the weather PDEs or by learning a better model?\nThe FourCastNet paper [Pathak, 2022] trains an Adaptive Fourier Neural Operator (AFNO) network [Guibas, 2022] to predict a collection of atmospheric variables at the next time step (6 hours into the future) given the current readout for those variables. The AFNO is an interesting choice here: it takes inspiration from both neural operators, which are designed to efficiently solve PDEs, and Vision Transformers (ViT), which can learn complex functions from large image datasets. We know that weather is well-modeled by PDEs, and the ERA 5 dataset is converted into images where each pixel location corresponds to a \\(.25^\\circ \\times .25^\\circ\\) latitude/longitude region, and each channel corresponds to a different atmospheric variable, so maybe some amalgam of neural operators and transformers makes sense."
  },
  {
    "objectID": "posts/FourCastNet/index.html#training",
    "href": "posts/FourCastNet/index.html#training",
    "title": "FourCastNet",
    "section": "Training",
    "text": "Training\nOne of the issues with almost every temporal process is that it has multiple time scales that we want to model. To predict the weather \\(k\\) time points into the future, FourCastNet must be run iteratively \\(k\\) times, and errors can accumulate so that inputs are out-of-domain. So, instead of training on the full temporal resolution of the data, FourCastNet is trained at 6-hour resolution. Probably badness would happen if it was trained at 1-hour resolution, and then run iteratively \\(6k\\) times. Interestingly, they first train on 6-hour predictions, then fine-tune to minimize 12-hour prediction errors when calling the network twice recursively."
  },
  {
    "objectID": "posts/FourCastNet/index.html#evaluation",
    "href": "posts/FourCastNet/index.html#evaluation",
    "title": "FourCastNet",
    "section": "Evaluation",
    "text": "Evaluation\nMost of the paper is devoted to evaluating the performance of the weather forecasts. They show that their predictions are qualitatively accurate on predicting the formation and trajectory of a cyclone and hurricane and patterns of an atmospheric river within the range of 2-4 days. They quantitatively compare the accuracy of the FourCastNet prediction to the ECMWF’s physics-based Integrated Forecasting System (IFS). Accuracy is worse (with a few exceptions), but comparable. More recent ML-based models, including GraphCast [Lam, 2023] and GenCast [Price, 2024] report performance better than ECMWF’s.\n\n\n\n\n\n\nFigure 3: Forecasting the formation of major storms [Pathak, 2022]\n\n\n\nThe improvement stressed in this work is computational, particularly when predicting an ensemble of forecasts. Here, they add Gaussian noise to the initial observations and produce slightly different forecasts to estimate the distribution. While the IFS forecast takes minutes on a giant supercomputing cluster, FourCastNet’s forecast takes 7 seconds on 4 A100s There’s a bit of apples to oranges in this comparison, both in terms of the problem and the type of computers when reporting just how much more efficient their approach is, but it is unquestionably more efficient. This is also the improvement that neural operators offer over classical methods for solving PDEs."
  },
  {
    "objectID": "posts/FourCastNet/index.html#thoughts",
    "href": "posts/FourCastNet/index.html#thoughts",
    "title": "FourCastNet",
    "section": "Thoughts",
    "text": "Thoughts\nOne closing question is about how ML solves this problem. Is it learning to model the weather in the same way that the governing physics equations do? Or is it more about learning what initial conditions are similar and memorizing? In some ways, memorization seems like it may be a step backwards – before numerical weather prediction was a thing, meteorologists did something closer to memorization:\n\nRichardson’s book opens with a discussion of then-current practice in the Meteorological Office. He describes the use of an Index of Weather Maps, constructed by classifying old synoptic charts into categories. The Index assisted the forecaster to find previous maps resembling the current one and therewith to deduce the likely development by studying the evolution of these earlier cases. But Richardson was not optimistic about this method. He wrote that “The forecast is based on the supposition that what the atmosphere did then, it will do again now. … The past history of the atmosphere is used, so to speak, as a full-scale working model of its present self”. … the Nautical Almanac, that marvel of accurate forecasting, is not based on the principle that astronomical history repeats itself in the aggregate. It would be safe to say that a particular disposition of stars, planets and satellites never occurs twice. Why then should we expect a present weather map to be exactly represented in a catalogue of past weather?\n\n– From [Lynch, 2008]\nThings I’m taking away from this paper:\n\nERA 5 is a cool dataset!\nIt’s going to allow ML to beat physics at weather forecasting, with lots of caveats about the classical work that goes into assimilating raw observations into these nicely gridded measurements, and probably lots of things I don’t understand about weather. Will be there be noticeable improvements to us in our weather forecasts soon??\nThere’s a lot of work to do on the details of what data is used, what is predicted, and how it is evaluated. I was happy to see that the ECMWF now has an experimental AIFS – the Artificial Intelligence/Integrated Forecasting System. They’ve released implementations of several of the SOTA models that you can get with pip install ai-models\nAFNO is an interesting choice because of (a) its connection to PDEs that underly many processes we want to model and (b) computational efficiency."
  },
  {
    "objectID": "posts/FourCastNet/index.html#about-the-afno",
    "href": "posts/FourCastNet/index.html#about-the-afno",
    "title": "FourCastNet",
    "section": "About the AFNO",
    "text": "About the AFNO\nWe spent some time trying to understand the AFNO, and its relationship to both PDEs and the transformer. A stated goal of the AFNO is to capture important properties of the transformer, but reduce the memory and computational requirements to not depend on the context length / number of image patches squared. This is important in the FourCastNet context, as each weather image has \\(1440/8 \\cdot 720/8 = 16,200\\) patches.\nEach AFNO block does the following:\n\nLet \\(X \\in \\mathcal{R}^{h \\times w \\times d}\\) be the input.\nUse the patch location \\((m,n)\\) to convert to frequency space: \\[z_{uv} = [DFT(X)]_{uv} = \\frac{1}{\\sqrt{mn}} \\sum_{mn} x_{mn} \\exp( - 2\\pi i (um/h+vn/w) ).\\] This can be viewed as token mixing, creating direct connections between every input spatial token \\(x_{uv}\\) and frequency token \\(z_{mn}\\).\nIn the frequency space, channels are adaptively mixed through 2-layer MLPs: \\[\\tilde{z}_{uv} = \\text{BlockMLP}(z_{uv}) = W_2 \\sigma( W_1 z_{uv} )\\] where \\(W_1, W_2 \\in \\mathcal{R}^{d \\times d}\\) are learned block-diagonal matrices. Note that this is described as part of the “spatial mixing” of AFNO, even though, as far as I can tell, it only mixes across channels.\nDemix tokens with the inverse Fourier transform: \\[y_{mn} = [IDFT(\\tilde{Z})]_{mn} = \\frac{1}{\\sqrt{mn}} \\sum_{uv} \\tilde{z}_{uv} \\exp( 2 \\pi i (um/h+vn/w) )\\]\nPerform another two-layer MLP to mix across channels in the spatial domain: \\[\\tilde{y}_{mn} = \\text{BlockMLP}(y_{mn})\\] This step is not mentioned, as far as we can tell, in the text of the AFNO paper, but is in Figure 2 and the AFNO code base. It is referred to as channel mixing.\n\nLike the MLP mixer, its relationship to the transformer is most obviously that there is some mixing across tokens and mixing across channels. As I understand it, mixing across tokens is through the Fourier transforms, and thus is not learned or input-dependent, but there are direct connections between all tokens.\nThe AFNO paper also shows that a self-attention layer can (ish) be expressed as a kernel integral: \\[\nAtt(X) = \\text{softmax}( XW_q(X W_k)^\\top / \\sqrt{d} ) X W_v\n\\] \\[\nAtt(X)[t] = \\sum_t X[t] \\kappa(s,t)\n\\] \\[\\kappa(s,t) = \\text{softmax}( XW_q(X W_k)^\\top / \\sqrt{d} ) W_v\\] Note that \\(\\kappa\\) is a kernel that depends on \\(X[t]\\). Viewing \\(X\\) as a function on the continuous space \\(D \\subset \\mathcal{R}^2\\) instead of as a matrix with values at discrete indices, they write this sum as an integral: \\[\\mathcal{K}(X)(s) = \\int_D \\kappa(s,t) X(t).\\] If \\(\\kappa\\) were shift-invariant (which is not generally the case), with \\(\\kappa(s,t) = \\kappa(s-t)\\), then we could compute this integral with convolution in the Fourier domain: \\[\\mathcal{K}(X)(s) = \\mathcal{F}^{-1}( \\mathcal{F}(\\kappa) \\cdot \\mathcal{F}(X))(s).\\] There is a tenuous relationship between these equations and the steps of the AFNO. However, as far as I can tell, the kernel in the AFNO does not depend on \\(X\\), which both makes it inherently different from a transformer, and removes the quadratic complexity."
  },
  {
    "objectID": "posts/FourCastNet/index.html#references",
    "href": "posts/FourCastNet/index.html#references",
    "title": "FourCastNet",
    "section": "References",
    "text": "References\n[Pathak, 2022] Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, Ashesh Chattopadhyay, Morteza Mardani, Thorsten Kurth, David Hall, Zongyi Li, Kamyar Azizzadenesheli, Pedram Hassanzadeh, Karthik Kashinath, and Animashree Anandkumar, “FourCastNet: A Global Data-driven High-resolution Weather Model using Adaptive Fourier Neural Operators”, 2022, url\n[Lynch, 2008] Peter Lynch, “The origins of computer weather prediction and climate modeling”, 2008, url\n[Charney, 1952] J. G. Charney, R. Fjortoft, & J. Von Neumann, “Numerical integration of the barotropic vorticity equation”, 1952, url\n[Haiden, 2021] T. Haiden, M. Janousek, F. Vitart, Z. Ben Bouallegue, L. Ferranti, F. Prates, and D. Richardson, “Evaluation of ECMWF forecasts, including the 2021 upgrade”, 2021, url\n[Guibas, 2022] John Guibas, Morteza Mardani, Zongyi Li, Andrew Tao, Anima Anandkumar, Bryan Catanzaro, “Adaptive Fourier Neural Operators: Efficient Token Mixers for Transformers”, 2022, url\n[Lam, 2023] Remi Lam, Alvaro Sanchez-Gonzalez, Matthew Willson, Peter Wirnsberger, Meire Fortunato, Ferran Alet, Suman Ravuri, Timo Ewalds, Zach Eaton-Rosen, Weihua Hu, Alexander Merose, Stephan Hoyer, George Holland, Oriol Vinyals, Jacklynn Stott, Alexander Pritzel, Shakir Mohamed, and Peter Battaglia, “GraphCast: Learning skillful medium-range global weather forecasting”, 2023, url\n[Price, 2024] Ilan Price, Alvaro Sanchez-Gonzalez, Ferran Alet, Tom R. Andersson, Andrew El-Kadi, Dominic Masters, Timo Ewalds, Jacklynn Stott, Shakir Mohamed, Peter Battaglia, Remi Lam and Matthew Willson, “GenCast: Diffusion-based ensemble forecasting for medium-range weather”, 2024, url"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Janelia CVML",
    "section": "",
    "text": "FourCastNet\n\n\n\n\n\n\nAIForScience\n\n\nNumericalMethods\n\n\nTransformers\n\n\nWeather\n\n\n\nWeather forecasting with Adaptive Fourier Neural Operators\n\n\n\n\n\nNov 8, 2024\n\n\nKristin Branson and Magdelena Schneider\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2024\n\n\nCVML organizers\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Computer Vision and Machine Learning at Janelia",
    "section": "",
    "text": "Researchers at Janelia have been participating in a weekly journal club on computer vision and machine learning (CVML) since 2014. This page will highlight some of our favorite papers."
  },
  {
    "objectID": "posts/2024-11-04-welcome.html",
    "href": "posts/2024-11-04-welcome.html",
    "title": "Welcome",
    "section": "",
    "text": "This page will highlight some papers recommended by Janelia’s computer vision and machine learning researchers."
  },
  {
    "objectID": "posts/2024-11-04-welcome.html#welcome-to-the-cvml-blog",
    "href": "posts/2024-11-04-welcome.html#welcome-to-the-cvml-blog",
    "title": "Welcome",
    "section": "",
    "text": "This page will highlight some papers recommended by Janelia’s computer vision and machine learning researchers."
  }
]